{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmembert.utils import Config\n",
    "from kmembert.models import TransformerAggregator\n",
    "from kmembert.utils import get_root, now\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "resume = \"kmembert-T2\"\n",
    "config = Config()\n",
    "config.resume = resume\n",
    "\n",
    "main_file = os.path.splitext(os.path.basename(sys.argv[0]))[0]\n",
    "session_id = f\"{main_file}_{now()}\"\n",
    "path_result = os.path.join(get_root(), \"results\", session_id)\n",
    "config.path_result = path_result\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nhead, num_layers, out_dim, time_dim = 8, 4, 2, 8\n",
    "\n",
    "model = TransformerAggregator(device, config, nhead, num_layers, out_dim, time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--data_folder\", type=str, default=\"ehr\", \n",
    "    help=\"data folder name\")\n",
    "parser.add_argument(\"-a\", \"--aggregator\", type=str, default=\"transformer\", \n",
    "    help=\"aggregator name\", choices=['conflation', 'sanity_check', 'sanity_check_transformer', 'transformer'])\n",
    "parser.add_argument(\"-r\", \"--resume\", type=str, default = \"kmembert-base\", \n",
    "    help=\"result folder in which the saved checkpoint will be reused\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=2, \n",
    "    help=\"number of epochs\")\n",
    "parser.add_argument(\"-nr\", \"--nrows\", type=int, default=None, \n",
    "    help=\"maximum number of samples for training and validation\")\n",
    "parser.add_argument(\"-k\", \"--print_every_k_batch\", type=int, default=1, \n",
    "    help=\"prints training loss every k batch\")\n",
    "parser.add_argument(\"-dt\", \"--days_threshold\", type=int, default=365, \n",
    "    help=\"days threshold to convert into classification task\")\n",
    "parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-4, \n",
    "    help=\"model learning rate\")\n",
    "parser.add_argument(\"-wg\", \"--weight_decay\", type=float, default=0, \n",
    "    help=\"the weight decay for L2 regularization\")\n",
    "parser.add_argument(\"-p\", \"--patience\", type=int, default=4, \n",
    "    help=\"number of decreasing accuracy epochs to stop the training\")\n",
    "parser.add_argument(\"-me\", \"--max_ehrs\", type=int, default=4, \n",
    "    help=\"maximum nusmber of ehrs to be used for multi ehrs prediction\")\n",
    "parser.add_argument(\"-nh\", \"--nhead\", type=int, default=8, \n",
    "    help=\"number of transformer heads\")\n",
    "parser.add_argument(\"-nl\", \"--num_layers\", type=int, default=4, \n",
    "    help=\"number of transformer layers\")\n",
    "parser.add_argument(\"-od\", \"--out_dim\", type=int, default=2, \n",
    "    help=\"transformer out_dim (1 regression or 2 density)\")\n",
    "parser.add_argument(\"-td\", \"--time_dim\", type=int, default=8, \n",
    "    help=\"transformer time_dim\")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m> DEVICE:  cpu\u001b[0m\n",
      "\u001b[1m> ROOT:    c:\\Users\\DIPIAZZA\\Documents\\CLB Projet\\Projet1\\Test Load BERTS\\KmemBERT\u001b[0m\n",
      "\u001b[1m> SESSION: c:\\Users\\DIPIAZZA\\Documents\\CLB Projet\\Projet1\\Test Load BERTS\\KmemBERT\\results\\ipykernel_launcher_22-04-28_09h57m46s\u001b[0m\n",
      "\u001b[1m\n",
      "Loading camembert and its tokenizer...\u001b[0m\n",
      "\u001b[1mResuming with model at kmembert-base...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccessfully loaded\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "Computing Health Bert predictions...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.01it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 376 bytes\n",
      "\u001b[92mSuccessfully computed 12 Health Bert outputs\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "Computing Health Bert predictions...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 248 bytes\n",
      "\u001b[92mSuccessfully computed 6 Health Bert outputs\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and dataloader\n",
    "from kmembert.dataset import PredictionsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from kmembert.utils import create_session, get_label_threshold, collate_fn\n",
    "\n",
    "path_dataset, _, device, config = create_session(args)\n",
    "\n",
    "assert (768 + args.time_dim) % args.nhead == 0, f'd_model (i.e. 768 + time_dim) must be divisible by nhead. Found time_dim {args.time_dim} and nhead {args.nhead}'\n",
    "\n",
    "config.label_threshold = get_label_threshold(config, path_dataset)\n",
    "\n",
    "train_dataset, test_dataset = PredictionsDataset.get_train_validation(\n",
    "    path_dataset, config, output_hidden_states=True, device=device)\n",
    "\n",
    "if not args.aggregator in ['conflation', 'sanity_check']:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "----- STARTING TRAINING -----\u001b[0m\n",
      "> EPOCH 0\n",
      "tensor([[1176.],\n",
      "        [   0.]])\n",
      "tensor([[-2.2158e+02,  1.1607e+03,  8.3102e+02, -1.0273e+03, -1.1548e+03,\n",
      "         -3.8240e+02,  1.0379e+02, -2.0070e+02],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [0-1]  -  Average loss: 0.043412  -  Time elapsed: 0m0s\n",
      "tensor([[2765.],\n",
      "        [   0.]])\n",
      "tensor([[-5.2141e+02,  2.7282e+03,  1.9550e+03, -2.4148e+03, -2.7156e+03,\n",
      "         -9.0005e+02,  2.4427e+02, -4.7071e+02],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [1-2]  -  Average loss: 0.233299  -  Time elapsed: 0m0s\n",
      "tensor([[446.],\n",
      "        [  0.]])\n",
      "tensor([[-8.3832e+01,  4.4058e+02,  3.1466e+02, -3.8993e+02, -4.3774e+02,\n",
      "         -1.4458e+02,  3.9254e+01, -7.6651e+01],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [2-3]  -  Average loss: 0.238442  -  Time elapsed: 0m0s\n",
      "tensor([[573.],\n",
      "        [127.],\n",
      "        [  0.]])\n",
      "tensor([[-1.0780e+02,  5.6586e+02,  4.0450e+02, -5.0082e+02, -5.6248e+02,\n",
      "         -1.8595e+02,  5.0481e+01, -9.8231e+01],\n",
      "        [ 9.9695e-01,  2.3658e-01,  8.7158e-01,  9.9131e-01,  9.5320e-01,\n",
      "         -1.8280e-01, -9.9838e-01,  4.3856e-01],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [3-4]  -  Average loss: 0.268508  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [4-5]  -  Average loss: 0.251996  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [5-6]  -  Average loss: 0.121704  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [6-7]  -  Average loss: 0.116133  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [7-8]  -  Average loss: -0.080820  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [8-9]  -  Average loss: 0.073934  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [9-10]  -  Average loss: 0.226718  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [10-11]  -  Average loss: 0.176288  -  Time elapsed: 0m0s\n",
      "tensor([[1826.],\n",
      "        [ 650.],\n",
      "        [   0.]])\n",
      "tensor([[-3.4423e+02,  1.8019e+03,  1.2908e+03, -1.5949e+03, -1.7932e+03,\n",
      "         -5.9415e+02,  1.6125e+02, -3.1115e+02],\n",
      "        [-1.9557e-01,  8.0321e-01,  2.8487e-01, -5.4244e-01,  3.6347e-01,\n",
      "          5.2369e-01,  6.7432e-01,  9.7785e-01],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [11-12]  -  Average loss: 0.080363  -  Time elapsed: 0m0s\n",
      "\u001b[95m    Training   | MAE: 2961 days - Global average loss: 0.145832 - Time elapsed: 0m4s\n",
      "\u001b[0m\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[299.],\n",
      "        [  0.]])\n",
      "tensor([[-5.6095e+01,  2.9557e+02,  2.1069e+02, -2.6158e+02, -2.9335e+02,\n",
      "         -9.6690e+01,  2.6258e+01, -5.1672e+01],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[3710.],\n",
      "        [   0.]])\n",
      "tensor([[-6.9972e+02,  3.6604e+03,  2.6234e+03, -3.2399e+03, -3.6438e+03,\n",
      "         -1.2079e+03,  3.2781e+02, -6.3128e+02],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[3772.],\n",
      "        [  62.],\n",
      "        [   0.]])\n",
      "tensor([[-7.1142e+02,  3.7215e+03,  2.6673e+03, -3.2940e+03, -3.7047e+03,\n",
      "         -1.2281e+03,  3.3329e+02, -6.4182e+02],\n",
      "        [ 9.2879e-01, -8.6680e-01, -8.0539e-01,  9.4331e-01,  7.6027e-01,\n",
      "         -5.9064e-01, -8.2884e-01,  9.1931e-01],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8091, -0.5039,  0.3453,  0.7167, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "\u001b[95m    Validation | MAE: 1296 days - Global average loss: 0.084389 - Time elapsed: 0m0s\n",
      "\u001b[0m\n",
      "\u001b[92m    Best loss so far\u001b[0m\n",
      "    Saving model state...\n",
      "    Saving predictions...\n",
      "    (Ended validation)\n",
      "\n",
      "> EPOCH 1\n",
      "tensor([[1176.],\n",
      "        [   0.]])\n",
      "tensor([[-2.2158e+02,  1.1607e+03,  8.3102e+02, -1.0273e+03, -1.1548e+03,\n",
      "         -3.8240e+02,  1.0379e+02, -2.0070e+02],\n",
      "        [ 3.1796e-01,  5.8347e-01, -7.2365e-01, -4.8283e-01,  3.3851e-01,\n",
      "          6.5692e-01, -1.7412e-01, -7.6092e-01]], grad_fn=<CatBackward0>)\n",
      "    [0-1]  -  Average loss: 0.215883  -  Time elapsed: 0m0s\n",
      "tensor([[1826.],\n",
      "        [ 650.],\n",
      "        [   0.]])\n",
      "tensor([[-3.4427e+02,  1.8019e+03,  1.2908e+03, -1.5948e+03, -1.7932e+03,\n",
      "         -5.9419e+02,  1.6129e+02, -3.1115e+02],\n",
      "        [-1.8158e-01,  7.9831e-01,  2.7185e-01, -5.5423e-01,  3.4927e-01,\n",
      "          5.3519e-01,  6.8427e-01,  9.7809e-01],\n",
      "        [ 3.1799e-01,  5.8349e-01, -7.2363e-01, -4.8284e-01,  3.3854e-01,\n",
      "          6.5694e-01, -1.7413e-01, -7.6090e-01]], grad_fn=<CatBackward0>)\n",
      "    [1-2]  -  Average loss: -0.495759  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3236,  0.6230, -0.8090, -0.5039,  0.3454,  0.7168, -0.1750, -0.8647]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [2-3]  -  Average loss: -0.673454  -  Time elapsed: 0m0s\n",
      "tensor([[573.],\n",
      "        [127.],\n",
      "        [  0.]])\n",
      "tensor([[-1.0783e+02,  5.6584e+02,  4.0447e+02, -5.0078e+02, -5.6246e+02,\n",
      "         -1.8600e+02,  5.0477e+01, -9.8236e+01],\n",
      "        [ 9.9638e-01,  2.3171e-01,  8.6841e-01,  9.9019e-01,  9.5452e-01,\n",
      "         -1.7305e-01, -9.9844e-01,  4.3938e-01],\n",
      "        [ 3.1804e-01,  5.8352e-01, -7.2358e-01, -4.8286e-01,  3.3859e-01,\n",
      "          6.5698e-01, -1.7416e-01, -7.6085e-01]], grad_fn=<CatBackward0>)\n",
      "    [3-4]  -  Average loss: -0.732471  -  Time elapsed: 0m0s\n",
      "tensor([[446.],\n",
      "        [  0.]])\n",
      "tensor([[-8.3863e+01,  4.4056e+02,  3.1464e+02, -3.8989e+02, -4.3772e+02,\n",
      "         -1.4463e+02,  3.9245e+01, -7.6664e+01],\n",
      "        [ 3.1807e-01,  5.8354e-01, -7.2356e-01, -4.8288e-01,  3.3862e-01,\n",
      "          6.5699e-01, -1.7419e-01, -7.6083e-01]], grad_fn=<CatBackward0>)\n",
      "    [4-5]  -  Average loss: -1.144877  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3237,  0.6231, -0.8089, -0.5040,  0.3455,  0.7168, -0.1751, -0.8646]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [5-6]  -  Average loss: -1.598256  -  Time elapsed: 0m0s\n",
      "tensor([[2765.],\n",
      "        [   0.]])\n",
      "tensor([[-5.2167e+02,  2.7279e+03,  1.9548e+03, -2.4145e+03, -2.7154e+03,\n",
      "         -9.0051e+02,  2.4415e+02, -4.7088e+02],\n",
      "        [ 3.1810e-01,  5.8358e-01, -7.2353e-01, -4.8291e-01,  3.3866e-01,\n",
      "          6.5701e-01, -1.7423e-01, -7.6079e-01]], grad_fn=<CatBackward0>)\n",
      "    [6-7]  -  Average loss: -1.698361  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3237,  0.6232, -0.8089, -0.5040,  0.3455,  0.7168, -0.1751, -0.8645]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [7-8]  -  Average loss: -1.935750  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6232, -0.8089, -0.5040,  0.3455,  0.7168, -0.1752, -0.8645]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [8-9]  -  Average loss: -2.591710  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6232, -0.8088, -0.5041,  0.3455,  0.7169, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [9-10]  -  Average loss: -2.569403  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6233, -0.8088, -0.5041,  0.3455,  0.7168, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [10-11]  -  Average loss: -2.922786  -  Time elapsed: 0m0s\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6233, -0.8088, -0.5041,  0.3455,  0.7168, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "    [11-12]  -  Average loss: -2.773812  -  Time elapsed: 0m0s\n",
      "\u001b[95m    Training   | MAE: 2403 days - Global average loss: -1.576730 - Time elapsed: 0m3s\n",
      "\u001b[0m\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6233, -0.8088, -0.5042,  0.3455,  0.7168, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[3710.],\n",
      "        [   0.]])\n",
      "tensor([[-7.0026e+02,  3.6599e+03,  2.6230e+03, -3.2393e+03, -3.6434e+03,\n",
      "         -1.2089e+03,  3.2748e+02, -6.3170e+02],\n",
      "        [ 3.1820e-01,  5.8376e-01, -7.2343e-01, -4.8308e-01,  3.3865e-01,\n",
      "          6.5700e-01, -1.7435e-01, -7.6068e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6233, -0.8088, -0.5042,  0.3455,  0.7168, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[3772.],\n",
      "        [  62.],\n",
      "        [   0.]])\n",
      "tensor([[-7.1197e+02,  3.7210e+03,  2.6668e+03, -3.2934e+03, -3.7043e+03,\n",
      "         -1.2291e+03,  3.3295e+02, -6.4225e+02],\n",
      "        [ 9.2548e-01, -8.7072e-01, -8.0955e-01,  9.3974e-01,  7.5628e-01,\n",
      "         -6.0417e-01, -8.3208e-01,  9.1668e-01],\n",
      "        [ 3.1820e-01,  5.8376e-01, -7.2343e-01, -4.8308e-01,  3.3865e-01,\n",
      "          6.5700e-01, -1.7435e-01, -7.6068e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[299.],\n",
      "        [  0.]])\n",
      "tensor([[-5.6138e+01,  2.9553e+02,  2.1065e+02, -2.6153e+02, -2.9332e+02,\n",
      "         -9.6772e+01,  2.6231e+01, -5.1706e+01],\n",
      "        [ 3.1820e-01,  5.8376e-01, -7.2343e-01, -4.8308e-01,  3.3865e-01,\n",
      "          6.5700e-01, -1.7435e-01, -7.6068e-01]], grad_fn=<CatBackward0>)\n",
      "tensor([[0.]])\n",
      "tensor([[ 0.3238,  0.6233, -0.8088, -0.5042,  0.3455,  0.7168, -0.1752, -0.8644]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "\u001b[95m    Validation | MAE: 1330 days - Global average loss: -1.437684 - Time elapsed: 0m0s\n",
      "\u001b[0m\n",
      "\u001b[92m    Best loss so far\u001b[0m\n",
      "    Saving model state...\n",
      "    Saving predictions...\n",
      "    (Ended validation)\n",
      "\n",
      "\u001b[94m-----  Ended Training  -----\n",
      "\u001b[0m\n",
      "Saving losses...\n",
      "[DONE]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4376836220423381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kmembert.training import train_and_validate\n",
    "\n",
    "model = TransformerAggregator(device, config, args.nhead, args.num_layers, args.out_dim, args.time_dim)\n",
    "train_and_validate(model, train_loader, test_loader, device, config, config.path_result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.5545e+02, -3.0557e+02, -5.5822e+01,  1.0581e+03,  4.1436e+02,\n",
       "         -2.1913e+02,  7.6069e+02, -1.1082e+02],\n",
       "        [ 5.5351e-01,  6.5893e-01,  4.8194e-01, -2.2832e-01, -4.5338e-01,\n",
       "          2.5027e-01, -6.7313e-01,  7.1734e-02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "a = torch.tensor([[1176.], [   0.]])\n",
    "lin = nn.Linear(1, 8)\n",
    "\n",
    "lin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d30e282fed7dc5f3c8822663add599cc2401cd25887475aec3f8e89f78362c8f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('kmembert_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
