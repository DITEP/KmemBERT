{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import & Chargement du modele\n",
    "from kmembert.utils import Config\n",
    "from kmembert.models import TransformerAggregator\n",
    "from kmembert.utils import get_root, now\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "resume = \"kmembert-T2\"\n",
    "config = Config()\n",
    "config.resume = resume\n",
    "\n",
    "main_file = os.path.splitext(os.path.basename(sys.argv[0]))[0]\n",
    "session_id = f\"{main_file}_{now()}\"\n",
    "path_result = os.path.join(get_root(), \"results\", session_id)\n",
    "config.path_result = path_result\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nhead, num_layers, out_dim, time_dim = 8, 4, 2, 8\n",
    "\n",
    "model = TransformerAggregator(device, config, nhead, num_layers, out_dim, time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--data_folder\", type=str, default=\"ehr\", \n",
    "    help=\"data folder name\")\n",
    "parser.add_argument(\"-a\", \"--aggregator\", type=str, default=\"transformer\", \n",
    "    help=\"aggregator name\", choices=['conflation', 'sanity_check', 'sanity_check_transformer', 'transformer'])\n",
    "parser.add_argument(\"-r\", \"--resume\", type=str, default = \"kmembert-base\", \n",
    "    help=\"result folder in which the saved checkpoint will be reused\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=2, \n",
    "    help=\"number of epochs\")\n",
    "parser.add_argument(\"-nr\", \"--nrows\", type=int, default=None, \n",
    "    help=\"maximum number of samples for training and validation\")\n",
    "parser.add_argument(\"-k\", \"--print_every_k_batch\", type=int, default=1, \n",
    "    help=\"prints training loss every k batch\")\n",
    "parser.add_argument(\"-dt\", \"--days_threshold\", type=int, default=365, \n",
    "    help=\"days threshold to convert into classification task\")\n",
    "parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-4, \n",
    "    help=\"model learning rate\")\n",
    "parser.add_argument(\"-wg\", \"--weight_decay\", type=float, default=0, \n",
    "    help=\"the weight decay for L2 regularization\")\n",
    "parser.add_argument(\"-p\", \"--patience\", type=int, default=4, \n",
    "    help=\"number of decreasing accuracy epochs to stop the training\")\n",
    "parser.add_argument(\"-me\", \"--max_ehrs\", type=int, default=4, \n",
    "    help=\"maximum nusmber of ehrs to be used for multi ehrs prediction\")\n",
    "parser.add_argument(\"-nh\", \"--nhead\", type=int, default=8, \n",
    "    help=\"number of transformer heads\")\n",
    "parser.add_argument(\"-nl\", \"--num_layers\", type=int, default=4, \n",
    "    help=\"number of transformer layers\")\n",
    "parser.add_argument(\"-od\", \"--out_dim\", type=int, default=2, \n",
    "    help=\"transformer out_dim (1 regression or 2 density)\")\n",
    "parser.add_argument(\"-td\", \"--time_dim\", type=int, default=8, \n",
    "    help=\"transformer time_dim\")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test avec testing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m> DEVICE:  cpu\u001b[0m\n",
      "\u001b[1m> ROOT:    c:\\Users\\DIPIAZZA\\Documents\\CLB Projet\\Projet1\\Test Load BERTS\\KmemBERT\u001b[0m\n",
      "\u001b[1m> SESSION: c:\\Users\\DIPIAZZA\\Documents\\CLB Projet\\Projet1\\Test Load BERTS\\KmemBERT\\results\\ipykernel_launcher_22-05-04_15h39m52s\u001b[0m\n",
      "output hidden states: True\n",
      "hb is None\n",
      "Dans le premier if\n",
      "\u001b[1m\n",
      "Loading camembert and its tokenizer...\u001b[0m\n",
      "\u001b[1mResuming with model at kmembert-base...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccessfully loaded\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "Computing Health Bert predictions...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:34<00:00,  9.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 376 bytes\n",
      "\u001b[92mSuccessfully computed 264 Health Bert outputs\n",
      "\u001b[0m\n",
      "\u001b[95m    Validation | MAE: 787 days - Global average loss: -0.200638 - Time elapsed: 0m4s\n",
      "\u001b[0m\n",
      "\u001b[92m    Best loss so far\u001b[0m\n",
      "    Saving model state...\n",
      "    Saving predictions...\n",
      "    (Ended validation)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and dataloader\n",
    "from kmembert.dataset import PredictionsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from kmembert.utils import create_session, get_label_threshold, collate_fn\n",
    "\n",
    "path_dataset, path_result, device, config = create_session(args)\n",
    "\n",
    "assert (768 + args.time_dim) % args.nhead == 0, f'd_model (i.e. 768 + time_dim) must be divisible by nhead. Found time_dim {args.time_dim} and nhead {args.nhead}'\n",
    "\n",
    "config.label_threshold = get_label_threshold(config, path_dataset)\n",
    "\n",
    "dataset = PredictionsDataset(path_dataset, config, output_hidden_states=True, device=device, train=False)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model.config.mode = \"density\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, roc_curve, r2_score\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "from kmembert.dataset import EHRDataset, PredictionsDataset\n",
    "from kmembert.utils import pretty_time, printc, create_session, save_json, get_label_threshold, get_error, time_survival_to_label, collate_fn, collate_fn_with_id\n",
    "from kmembert.models import HealthBERT, TransformerAggregator, Conflation, SanityCheck\n",
    "\n",
    "test_losses = []\n",
    "validation = True\n",
    "model.eval()\n",
    "predictions, test_labels, stds, noigr = [], [], [], []\n",
    "test_start_time = time()\n",
    "\n",
    "total_loss = 0\n",
    "for i, (*data, labels) in enumerate(loader):\n",
    "    noigr.append(id)\n",
    "\n",
    "    loss, outputs = model.step(*data, labels)\n",
    "    \n",
    "    if model.mode == 'classif':\n",
    "        predictions += torch.softmax(outputs, dim=1).argmax(axis=1).tolist()\n",
    "    elif model.mode == 'regression':\n",
    "        predictions += outputs.flatten().tolist()\n",
    "    elif model.mode == 'density':\n",
    "        mus, log_vars = outputs\n",
    "        predictions += mus.tolist()\n",
    "        stds += torch.exp(log_vars/2).tolist()\n",
    "    elif model.mode == 'multi':\n",
    "        if model.config.mode == 'density' or (model.config.mode == 'classif' and model.out_dim == 2):\n",
    "            mu, log_var = outputs\n",
    "            predictions.append(mu.item())\n",
    "            stds.append(torch.exp(log_var/2).item())\n",
    "        else:\n",
    "            predictions.append(outputs.item())\n",
    "    else:\n",
    "        raise ValueError(f'Mode {model.mode} unknown')\n",
    "    \n",
    "    test_labels += labels.tolist()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "mean_loss = total_loss/(config.batch_size*len(loader))\n",
    "\n",
    "if test_losses is not None:\n",
    "    test_losses.append(mean_loss)\n",
    "\n",
    "error = get_error(test_labels, predictions, config.mean_time_survival)\n",
    "printc(f\"    {'Validation' if validation else 'Test'} | MAE: {int(error)} days - Global average loss: {mean_loss:.6f} - Time elapsed: {pretty_time(time()-test_start_time)}\\n\", 'RESULTS')\n",
    "\n",
    "if validation:\n",
    "    if mean_loss < model.best_loss:\n",
    "        model.best_loss = mean_loss\n",
    "        printc('    Best loss so far', 'SUCCESS')\n",
    "        print('    Saving model state...')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': model.optimizer.state_dict(),\n",
    "            #'scheduler': model.scheduler.state_dict(),\n",
    "            'best_loss': model.best_loss,\n",
    "            'epoch': 0,\n",
    "            'tokenizer': model.tokenizer if hasattr(model, 'tokenizer') else None\n",
    "        }\n",
    "        #torch.save(state, os.path.join(path_result, './checkpoint.pth'))\n",
    "        model.early_stopping = 0\n",
    "    else: \n",
    "        model.early_stopping += 1\n",
    "        #return mean_loss\n",
    "\n",
    "print('    Saving predictions...')\n",
    "#save_json(path_result, \"test\", {\"labels\": test_labels, \"predictions\": predictions, \"stds\": stds, \"noigr\": noigr})\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "if len(stds) > 0:\n",
    "    n_points = 20\n",
    "    resize_factor = 20\n",
    "    gaussian_predictions = np.random.normal(predictions, np.array(stds)/resize_factor, size=(n_points, len(predictions))).flatten().clip(0, 1)\n",
    "    associated_labels = np.tile(test_labels, n_points)\n",
    "    sns.kdeplot(\n",
    "        data={'Predictions': gaussian_predictions, 'Labels': associated_labels}, \n",
    "        y='Predictions', x='Labels', clip=((0, 1), (0, 1)),\n",
    "        fill=True, thresh=0, levels=100, cmap=\"mako\",\n",
    "    )\n",
    "    plt.title('Prediction distributions over labels')\n",
    "    plt.savefig(os.path.join(path_result, \"correlations_distributions.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.scatter(test_labels, stds)\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Standard Deviations\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, max(stds))\n",
    "    plt.title(\"Labels and corresponding standard deviations\")\n",
    "    plt.savefig(os.path.join(path_result, \"stds.png\"))\n",
    "    plt.close()\n",
    "\n",
    "all_errors = get_error(test_labels, predictions, config.mean_time_survival, mean=False)\n",
    "\n",
    "plt.scatter(test_labels, all_errors)\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, max(all_errors))\n",
    "plt.title(\"MAE distribution\")\n",
    "plt.savefig(os.path.join(path_result, \"mae_distribution.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.scatter(test_labels, predictions)\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Predictions / Labels correlation\")\n",
    "plt.savefig(os.path.join(path_result, \"correlations.png\"))\n",
    "plt.close()\n",
    "\n",
    "errors_dict = defaultdict(list)\n",
    "for mae, label in zip(all_errors.tolist(), test_labels.tolist()):\n",
    "    quantile = np.floor(label*10)\n",
    "    errors_dict[quantile].append(mae)\n",
    "ape_per_quantile = sorted([(quantile, np.mean(l), np.std(l)) for quantile, l in errors_dict.items()])\n",
    "\n",
    "\n",
    "metrics = {}\n",
    "metrics[\"correlation\"] = np.corrcoef(predictions, test_labels)[0,1]\n",
    "metrics[\"label_mae\"] = np.mean(np.abs(predictions - test_labels))\n",
    "metrics[\"r2_score\"] = r2_score(test_labels, predictions)\n",
    "\n",
    "for days in [30,90,180,270,360]:\n",
    "    label = time_survival_to_label(days, config.mean_time_survival)\n",
    "    bin_predictions = (predictions >= label).astype(int)\n",
    "    bin_labels = (test_labels >= label).astype(int)\n",
    "    \n",
    "    days = f\"{days} days\"\n",
    "    metrics[days] = {}\n",
    "    metrics[days]['accuracy'] = accuracy_score(bin_labels, bin_predictions)\n",
    "    metrics[days]['balanced_accuracy'] = balanced_accuracy_score(bin_labels, bin_predictions)\n",
    "    metrics[days]['f1_score'] = f1_score(bin_labels, bin_predictions, average=None).tolist()\n",
    "    \n",
    "try:\n",
    "    # Error when only one class (in practice it happens only on the `ehr` sanity-check dataset)\n",
    "    \n",
    "    bin_labels = (test_labels >= 0.5).astype(int)\n",
    "    metrics['auc'] = roc_auc_score(bin_labels, predictions).tolist()\n",
    "    fpr, tpr, _ = roc_curve(bin_labels, predictions)\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlabel(\"False Positive rate\")\n",
    "    plt.ylabel(\"True Positive rate\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.savefig(os.path.join(path_result, \"roc_curve.png\"))\n",
    "    plt.close()\n",
    "except:\n",
    "    printc(\"    Error while computing ROC curve\", \"WARNING\")\n",
    "\n",
    "if not validation:\n",
    "    print(\"Classification metrics:\\n\", metrics)\n",
    "\n",
    "save_json(path_result, 'results', \n",
    "    {'mae': error,\n",
    "    'mean_loss': mean_loss,\n",
    "    'metrics': metrics,\n",
    "    'ape_per_quantile': ape_per_quantile})\n",
    "\n",
    "print(f\"    (Ended {'validation' if validation else 'testing'})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days in [30,90,180,270,360]:\n",
    "    label = time_survival_to_label(days, config.mean_time_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36237184837822667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_survival_to_label(360, config.mean_time_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d30e282fed7dc5f3c8822663add599cc2401cd25887475aec3f8e89f78362c8f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('kmembert_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
