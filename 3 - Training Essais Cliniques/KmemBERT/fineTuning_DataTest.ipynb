{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification-T2 - Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mResuming with model at kmembert-T2...\u001b[0m\n",
      "\u001b[92mSuccessfully loaded\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load T2 model\n",
    "from kmembert.utils import Config\n",
    "from kmembert.models import TransformerAggregator\n",
    "from kmembert.utils import get_root, now\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "resume = \"kmembert-T2\"\n",
    "config = Config()\n",
    "config.resume = resume\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nhead, num_layers, out_dim, time_dim = 8, 4, 2, 8\n",
    "\n",
    "# Init model\n",
    "model = TransformerAggregator(device, config, nhead, num_layers, out_dim, time_dim)\n",
    "\n",
    "# Load the model\n",
    "model.resume(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArgParse\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--data_folder\", type=str, default=\"ehr\", \n",
    "    help=\"data folder name\")\n",
    "parser.add_argument(\"-a\", \"--aggregator\", type=str, default=\"transformer\", \n",
    "    help=\"aggregator name\", choices=['conflation', 'sanity_check', 'sanity_check_transformer', 'transformer'])\n",
    "parser.add_argument(\"-r\", \"--resume\", type=str, default = \"kmembert-base\", \n",
    "    help=\"result folder in which the saved checkpoint will be reused\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=2, \n",
    "    help=\"number of epochs\")\n",
    "parser.add_argument(\"-nr\", \"--nrows\", type=int, default=None, \n",
    "    help=\"maximum number of samples for training and validation\")\n",
    "parser.add_argument(\"-k\", \"--print_every_k_batch\", type=int, default=1, \n",
    "    help=\"prints training loss every k batch\")\n",
    "parser.add_argument(\"-dt\", \"--days_threshold\", type=int, default=365, \n",
    "    help=\"days threshold to convert into classification task\")\n",
    "parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-4, \n",
    "    help=\"model learning rate\")\n",
    "parser.add_argument(\"-wg\", \"--weight_decay\", type=float, default=0, \n",
    "    help=\"the weight decay for L2 regularization\")\n",
    "parser.add_argument(\"-p\", \"--patience\", type=int, default=4, \n",
    "    help=\"number of decreasing accuracy epochs to stop the training\")\n",
    "parser.add_argument(\"-me\", \"--max_ehrs\", type=int, default=4, \n",
    "    help=\"maximum nusmber of ehrs to be used for multi ehrs prediction\")\n",
    "parser.add_argument(\"-nh\", \"--nhead\", type=int, default=8, \n",
    "    help=\"number of transformer heads\")\n",
    "parser.add_argument(\"-nl\", \"--num_layers\", type=int, default=4, \n",
    "    help=\"number of transformer layers\")\n",
    "parser.add_argument(\"-od\", \"--out_dim\", type=int, default=2, \n",
    "    help=\"transformer out_dim (1 regression or 2 density)\")\n",
    "parser.add_argument(\"-td\", \"--time_dim\", type=int, default=8, \n",
    "    help=\"transformer time_dim\")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m> DEVICE:  cpu\u001b[0m\n",
      "\u001b[1m> ROOT:    c:\\Users\\DIPIAZZA\\Documents\\CLBProjet\\VirtualMachine_T2_Classification_Phase_I\\KmemBERT\u001b[0m\n",
      "\u001b[1m> SESSION: c:\\Users\\DIPIAZZA\\Documents\\CLBProjet\\VirtualMachine_T2_Classification_Phase_I\\KmemBERT\\results\\ipykernel_launcher_22-08-02_15h15m13s\u001b[0m\n",
      "str_date:  19991203\n",
      "str_date:  19990913\n",
      "str_date:  19991203\n",
      "str_date:  19991007\n",
      "str_date:  19991203\n",
      "str_date:  19991028\n",
      "str_date:  19991203\n",
      "str_date:  19991116\n",
      "str_date:  20010316\n",
      "str_date:  19991129\n",
      "str_date:  20030602\n",
      "str_date:  20000307\n",
      "str_date:  20010506\n",
      "str_date:  20000410\n",
      "str_date:  20010506\n",
      "str_date:  20000413\n",
      "str_date:  20010506\n",
      "str_date:  20000425\n",
      "str_date:  20010506\n",
      "str_date:  20000427\n",
      "str_date:  20001116\n",
      "str_date:  20000607\n",
      "str_date:  20010316\n",
      "str_date:  20000619\n",
      "str_date:  20001116\n",
      "str_date:  20000719\n",
      "str_date:  20001116\n",
      "str_date:  20000719\n",
      "str_date:  20001116\n",
      "str_date:  20000802\n",
      "str_date:  20030602\n",
      "str_date:  20000912\n",
      "str_date:  20030602\n",
      "str_date:  20000927\n",
      "str_date:  20030602\n",
      "str_date:  20001003\n",
      "str_date:  20010316\n",
      "str_date:  20001018\n",
      "str_date:  20011205\n",
      "str_date:  20001122\n",
      "str_date:  20011205\n",
      "str_date:  20010322\n",
      "str_date:  20011205\n",
      "str_date:  20010402\n",
      "str_date:  20011205\n",
      "str_date:  20010402\n",
      "str_date:  20020202\n",
      "str_date:  20011116\n",
      "str_date:  20020202\n",
      "str_date:  20011121\n",
      "str_date:  20020202\n",
      "str_date:  20011121\n",
      "str_date:  20020202\n",
      "str_date:  20011121\n",
      "str_date:  20020710\n",
      "str_date:  20020125\n",
      "str_date:  20020710\n",
      "str_date:  20020208\n",
      "str_date:  20020710\n",
      "str_date:  20020213\n",
      "str_date:  20020710\n",
      "str_date:  20020213\n",
      "str_date:  20170312\n",
      "str_date:  20151223\n",
      "str_date:  20170312\n",
      "str_date:  20160205\n",
      "str_date:  20170312\n",
      "str_date:  20160212\n",
      "str_date:  20170312\n",
      "str_date:  20161006\n",
      "str_date:  20190420\n",
      "str_date:  20161018\n",
      "str_date:  20180326\n",
      "str_date:  20161018\n",
      "str_date:  20180409\n",
      "str_date:  20161125\n",
      "str_date:  20180326\n",
      "str_date:  20161205\n",
      "str_date:  20190420\n",
      "str_date:  20161207\n",
      "str_date:  20180326\n",
      "str_date:  20161209\n",
      "str_date:  20180326\n",
      "str_date:  20161216\n",
      "str_date:  20170608\n",
      "str_date:  20170117\n",
      "str_date:  20190420\n",
      "str_date:  20170125\n",
      "str_date:  20170425\n",
      "str_date:  20170130\n",
      "str_date:  20180409\n",
      "str_date:  20170202\n",
      "str_date:  20190420\n",
      "str_date:  20170213\n",
      "str_date:  20180212\n",
      "str_date:  20170404\n",
      "str_date:  20171016\n",
      "str_date:  20170406\n",
      "str_date:  20170425\n",
      "str_date:  20170407\n",
      "str_date:  20170425\n",
      "str_date:  20170410\n",
      "str_date:  20180212\n",
      "str_date:  20170418\n",
      "str_date:  20170425\n",
      "str_date:  20170418\n",
      "str_date:  20171016\n",
      "str_date:  20170511\n",
      "str_date:  20180409\n",
      "str_date:  20170511\n",
      "str_date:  20180409\n",
      "str_date:  20170515\n",
      "str_date:  20171016\n",
      "str_date:  20170516\n",
      "str_date:  20171016\n",
      "str_date:  20170530\n",
      "str_date:  20180212\n",
      "str_date:  20170606\n",
      "str_date:  20180212\n",
      "str_date:  20170622\n",
      "str_date:  20181030\n",
      "str_date:  20180926\n",
      "str_date:  20181219\n",
      "str_date:  20180928\n",
      "str_date:  20190411\n",
      "str_date:  20181001\n",
      "str_date:  20181219\n",
      "str_date:  20181001\n",
      "str_date:  20181030\n",
      "str_date:  20181008\n",
      "str_date:  20181030\n",
      "str_date:  20181009\n",
      "str_date:  20181219\n",
      "str_date:  20181017\n",
      "str_date:  20190411\n",
      "str_date:  20181019\n",
      "str_date:  20181107\n",
      "str_date:  20181019\n",
      "str_date:  20181030\n",
      "str_date:  20181022\n",
      "str_date:  20181107\n",
      "str_date:  20181023\n",
      "str_date:  20190411\n",
      "str_date:  20181025\n",
      "str_date:  20181219\n",
      "str_date:  20181029\n",
      "str_date:  20181206\n",
      "str_date:  20181029\n",
      "str_date:  20181206\n",
      "str_date:  20181031\n",
      "str_date:  20190411\n",
      "str_date:  20181105\n",
      "str_date:  20181206\n",
      "str_date:  20181107\n",
      "str_date:  20181107\n",
      "str_date:  20181107\n",
      "str_date:  20181206\n",
      "str_date:  20181113\n",
      "str_date:  20181107\n",
      "str_date:  20181113\n",
      "\u001b[1m\n",
      "Loading camembert and its tokenizer...\u001b[0m\n",
      "if config.resume from health_bert.py\n",
      "\u001b[1mResuming with model at kmembert-base...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccessfully loaded\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "Computing Health Bert predictions...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:48<00:00,  2.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 656 bytes\n",
      "\u001b[92mSuccessfully computed 80 Health Bert outputs\n",
      "\u001b[0m\n",
      "str_date:  20180110\n",
      "str_date:  20170614\n",
      "str_date:  20180110\n",
      "str_date:  20170619\n",
      "str_date:  20180110\n",
      "str_date:  20170620\n",
      "str_date:  20180110\n",
      "str_date:  20170626\n",
      "str_date:  20181120\n",
      "str_date:  20180129\n",
      "str_date:  20181120\n",
      "str_date:  20180302\n",
      "str_date:  20181120\n",
      "str_date:  20180306\n",
      "str_date:  20181120\n",
      "str_date:  20180313\n",
      "str_date:  20190128\n",
      "str_date:  20180831\n",
      "str_date:  20190128\n",
      "str_date:  20180904\n",
      "str_date:  20190128\n",
      "str_date:  20180907\n",
      "str_date:  20190128\n",
      "str_date:  20180917\n",
      "\u001b[1m\n",
      "Computing Health Bert predictions...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 248 bytes\n",
      "\u001b[92mSuccessfully computed 12 Health Bert outputs\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and dataloader\n",
    "from kmembert.dataset import PredictionsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from kmembert.utils import create_session, get_label_threshold, collate_fn, collate_fn_with_id\n",
    "\n",
    "path_dataset, _, device, config = create_session(args)\n",
    "\n",
    "assert (768 + args.time_dim) % args.nhead == 0, f'd_model (i.e. 768 + time_dim) must be divisible by nhead. Found time_dim {args.time_dim} and nhead {args.nhead}'\n",
    "\n",
    "config.label_threshold = get_label_threshold(config, path_dataset)\n",
    "\n",
    "train_dataset, test_dataset = PredictionsDataset.get_train_validation(\n",
    "    path_dataset, config, output_hidden_states=True, device=device)\n",
    "\n",
    "if not args.aggregator in ['conflation', 'sanity_check']:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "----- STARTING TRAINING -----\u001b[0m\n",
      "ON EST DANS LE SCHEDULER DE INTERFACE.PY\n",
      "\u001b[104m\u001b[97m> EPOCH 0/1\u001b[0m\n",
      "\u001b[95m    Training | Epoch: 0 - Mean Loss: 0.843885 - Time elapsed: 0m7s\u001b[0m\n",
      "\u001b[95m    Testing | Epoch: 0 - Mean Loss: 1.519836 - Time elapsed: 0m0s\n",
      "\u001b[0m\n",
      "\u001b[92m    Best loss so far\u001b[0m\n",
      "    Saving model state...\n",
      "    Saving predictions...   \n",
      "\u001b[92m   Predictions and Labels saved.   \u001b[0m\n",
      "    (Ended validation)\n",
      "\n",
      "\u001b[104m\u001b[97m> EPOCH 1/1\u001b[0m\n",
      "\u001b[95m    Training | Epoch: 1 - Mean Loss: 0.826050 - Time elapsed: 0m7s\u001b[0m\n",
      "\u001b[95m    Testing | Epoch: 1 - Mean Loss: 1.498594 - Time elapsed: 0m0s\n",
      "\u001b[0m\n",
      "\u001b[92m    Best loss so far\u001b[0m\n",
      "    Saving model state...\n",
      "    Saving predictions...   \n",
      "\u001b[92m   Predictions and Labels saved.   \u001b[0m\n",
      "    (Ended validation)\n",
      "\n",
      "\u001b[94m-----  Ended Training  -----\n",
      "\u001b[0m\n",
      "   Saving losses...   \n",
      "\u001b[92m   Losses saved...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4985936085383098"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kmembert.training import train_and_validate\n",
    "\n",
    "train_and_validate(model, train_loader, test_loader, device, config, config.path_result)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('clb_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3017c399632bdad99ff7d78fdd8a75c4df8c74c804f4832978fc1a75e7107017"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
