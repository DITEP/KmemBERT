{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rockl33/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f2a2d56084040994c0d71f1fc7b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18221ebf11cf460cacbded649a824c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "\n",
    "text_1 = \"Who was Jim Henson ?\"\n",
    "text_2 = \"Jim Henson was a puppeteer\"\n",
    "\n",
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rockl33/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f0e57af62549dcb761480dec695936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last_hidden_state'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2627,  1108,  3104,  1124, 15703,   136,   102,  3104,  1124,\n",
       "         15703,  1108,   170, 16797,  8284,   102]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1105, 5709, 2780, 5709, 102]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"andand treeand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', '##and', 'tree', '##and', 'a', '##aa', '##a']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"andand treeand aaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n",
      "28997\n",
      "tensor([-1.3126e-02,  1.0533e-02,  5.6665e-02, -2.8865e-02,  3.2958e-02,\n",
      "         3.1519e-02, -4.0582e-03,  5.4731e-03, -6.7931e-03, -2.2411e-02,\n",
      "        -2.2471e-02, -1.0006e-02,  3.6837e-02, -2.6327e-02, -3.2121e-02,\n",
      "        -2.3509e-02,  2.1845e-03, -2.7116e-02, -3.2145e-02,  1.9745e-02,\n",
      "        -3.9055e-02, -2.5465e-02, -1.1840e-02, -1.0097e-02,  6.3261e-03,\n",
      "        -3.1771e-02, -4.0782e-02, -1.5294e-02,  5.3327e-04,  1.7529e-02,\n",
      "        -4.9256e-02, -2.1151e-02,  3.6940e-02, -2.8220e-02,  7.0020e-03,\n",
      "        -2.1455e-03,  2.4524e-02, -7.7240e-03, -3.0733e-02, -2.5564e-03,\n",
      "        -1.6988e-02, -5.2824e-03, -5.5316e-03,  1.5267e-02,  9.4205e-03,\n",
      "         1.4405e-02,  5.3472e-03, -2.6992e-02, -2.7723e-02, -8.0013e-03,\n",
      "        -2.5975e-02,  9.0082e-03, -2.6768e-02,  4.6433e-03,  3.3718e-02,\n",
      "        -6.9292e-03,  5.3346e-03,  1.4689e-02,  2.8722e-02, -2.7926e-02,\n",
      "        -2.0128e-02, -2.1669e-02, -1.5290e-02, -1.2853e-02, -1.7714e-02,\n",
      "        -2.7043e-03,  1.8152e-02, -6.3021e-03, -1.1325e-02, -4.5023e-02,\n",
      "        -2.5179e-02, -3.9293e-02, -3.1490e-03,  1.6295e-03, -1.3099e-02,\n",
      "        -1.4166e-03,  5.1081e-03,  1.2919e-02,  3.8344e-02,  1.6476e-02,\n",
      "         7.9031e-03, -3.2941e-02,  4.5104e-02, -1.6320e-02,  6.3815e-03,\n",
      "         2.1193e-02,  1.3046e-02, -6.5855e-03,  6.4963e-03,  4.6959e-02,\n",
      "        -2.2869e-03, -2.4052e-02,  7.5311e-03,  3.2143e-02, -5.3939e-03,\n",
      "         8.7781e-04, -3.5950e-04,  3.5735e-02,  4.2494e-03,  5.1934e-03,\n",
      "        -2.5796e-02, -1.7126e-02, -3.2917e-02, -9.6491e-03,  1.5702e-02,\n",
      "         6.2574e-03, -1.3404e-02,  2.2497e-02, -1.1022e-02,  2.9306e-02,\n",
      "         2.6237e-02, -1.9178e-02,  1.4094e-02,  3.7885e-02,  4.9088e-03,\n",
      "        -1.7766e-02, -6.7822e-03,  1.9818e-02, -2.4757e-02, -5.9451e-03,\n",
      "        -1.3301e-02, -8.2485e-04,  1.0794e-02, -4.3491e-02,  3.9225e-02,\n",
      "         8.0282e-03, -2.5563e-02, -1.1541e-02, -2.0147e-02, -3.5727e-03,\n",
      "        -2.3013e-02,  5.0474e-03, -1.5690e-02,  1.9621e-02,  1.7568e-04,\n",
      "         3.9808e-02,  2.0684e-02, -4.4848e-02,  1.0344e-02, -2.4997e-02,\n",
      "         5.1419e-03,  1.6570e-02, -5.4205e-02, -9.9921e-03, -2.8205e-03,\n",
      "        -6.8016e-03,  3.2310e-02,  1.3652e-02,  1.5681e-02,  5.2154e-03,\n",
      "         1.3897e-02, -3.8288e-03,  2.1488e-02,  4.7349e-02,  9.7149e-03,\n",
      "         2.7248e-02, -3.1487e-03,  3.7931e-03,  1.5329e-02,  2.2180e-02,\n",
      "         1.2901e-03,  1.3067e-02, -4.9320e-03,  1.8811e-03, -5.8728e-03,\n",
      "        -1.3896e-03, -1.6744e-02, -3.4924e-02,  6.7492e-02, -1.5828e-02,\n",
      "         1.3121e-02,  2.3901e-02,  4.2859e-03,  1.7401e-02,  2.2272e-04,\n",
      "         2.3303e-02, -4.7896e-03, -2.2592e-02,  6.9598e-03,  1.6798e-02,\n",
      "         2.1344e-02,  1.1412e-02,  4.1022e-02,  2.5847e-02, -3.1988e-03,\n",
      "        -1.2087e-03, -2.6234e-02,  3.2906e-04, -1.6996e-02, -5.8808e-04,\n",
      "        -1.0075e-02,  1.0064e-03,  1.9478e-02,  5.1544e-03,  1.0555e-02,\n",
      "        -3.0083e-02, -5.0544e-02, -3.3028e-03, -7.1842e-03,  8.2145e-03,\n",
      "         1.1630e-02, -8.9576e-03, -2.9772e-02,  2.1753e-02, -2.5232e-02,\n",
      "         3.2146e-03, -3.1963e-03,  1.9332e-02, -2.4536e-02,  2.7187e-02,\n",
      "        -3.2791e-02,  5.8742e-02,  1.9060e-02,  2.2063e-04,  4.1624e-02,\n",
      "         4.7404e-03, -1.4629e-03, -7.5283e-03, -2.0901e-03, -1.7546e-03,\n",
      "         4.1068e-02, -9.6040e-04,  1.2553e-03, -6.6522e-03, -1.1173e-02,\n",
      "         1.4947e-02,  1.8884e-02,  1.1531e-02,  3.2071e-02,  2.6663e-02,\n",
      "        -7.7286e-03, -2.5090e-02, -4.5075e-02,  1.5624e-02, -5.1540e-02,\n",
      "        -3.1386e-02,  8.6760e-03, -4.5322e-04, -4.1076e-03,  2.1470e-02,\n",
      "         1.6274e-02,  1.5051e-02, -1.3669e-02,  3.1199e-02,  1.9009e-02,\n",
      "        -4.4127e-03, -3.7694e-03, -1.7682e-02, -2.4346e-03,  2.5864e-02,\n",
      "         5.0210e-03,  2.5232e-02, -6.0044e-03,  8.9749e-03,  5.0304e-03,\n",
      "        -1.0942e-02, -4.9329e-04, -9.2783e-03, -5.6548e-03,  7.8405e-03,\n",
      "         5.3215e-03,  1.7674e-02,  1.6514e-03, -5.4726e-03,  4.9027e-02,\n",
      "        -1.1309e-02,  4.6256e-03,  1.2699e-02,  3.4254e-02, -8.6147e-03,\n",
      "        -2.0983e-02, -1.1103e-02, -1.0256e-02,  4.8609e-03,  1.5029e-02,\n",
      "        -1.1045e-02,  1.3462e-02,  2.1748e-02,  3.9804e-02,  1.6755e-02,\n",
      "        -4.8208e-03,  2.6938e-02,  2.3948e-02, -4.4334e-03,  3.7078e-02,\n",
      "        -7.7045e-03,  9.6942e-03,  1.0899e-02,  6.4075e-03,  1.0247e-03,\n",
      "         3.6181e-02, -1.0874e-02,  4.2818e-02, -3.5645e-02,  2.5156e-02,\n",
      "        -5.0328e-02, -1.4390e-02,  2.3962e-04, -7.9514e-03, -2.1256e-02,\n",
      "        -2.0937e-03,  1.7929e-02, -1.4381e-03, -4.4173e-03,  1.8166e-02,\n",
      "         1.6068e-02,  1.0109e-03, -1.8107e-02, -1.0460e-02, -1.1365e-02,\n",
      "         2.1804e-02,  5.1601e-03,  1.8586e-02, -2.9000e-02,  8.4251e-03,\n",
      "        -8.6203e-03,  9.5513e-03,  1.8150e-02, -6.9811e-03,  8.7211e-03,\n",
      "        -3.3245e-02, -6.9576e-03, -4.3624e-04,  2.5364e-02, -2.2425e-02,\n",
      "        -2.0868e-03, -1.2573e-02, -1.9577e-02, -2.1779e-02,  6.9230e-03,\n",
      "        -2.5904e-02,  4.6044e-02, -1.7703e-02,  2.8450e-02,  2.2083e-02,\n",
      "         6.3386e-03, -2.3151e-02, -9.1219e-03,  2.7029e-02,  3.9305e-02,\n",
      "         7.0574e-03,  5.8736e-03,  1.8560e-02, -2.5655e-02,  1.6968e-02,\n",
      "        -7.3564e-03, -1.2527e-02, -2.3648e-02,  2.3363e-02,  4.9911e-03,\n",
      "         5.6033e-03, -9.0435e-03, -8.1178e-04,  2.3469e-03, -8.8823e-03,\n",
      "         3.7189e-02, -3.6338e-02,  2.8389e-02,  3.0837e-02,  2.6043e-03,\n",
      "        -7.3158e-03, -2.2373e-02,  7.3983e-03,  3.7192e-02, -1.3612e-02,\n",
      "         1.8524e-02,  1.7581e-02, -2.1881e-02,  1.4822e-02, -7.0316e-03,\n",
      "        -1.3779e-02,  8.6766e-03,  7.5391e-03, -6.3505e-05, -1.2450e-02,\n",
      "        -1.6628e-02,  1.2367e-03, -1.8328e-02,  2.8814e-02, -1.1439e-02,\n",
      "        -1.0711e-03,  1.1541e-02,  2.2176e-02,  4.4511e-03, -1.1048e-02,\n",
      "         4.6219e-02, -2.4329e-02,  2.7802e-02, -2.2488e-02,  1.4140e-03,\n",
      "         1.5054e-03,  6.2514e-03,  1.0461e-02,  1.7869e-02, -2.5172e-02,\n",
      "        -7.0405e-03,  8.7867e-03, -1.4478e-02, -2.4737e-02, -2.9656e-02,\n",
      "        -9.7902e-04,  2.9246e-03,  5.2983e-03, -1.2218e-02,  4.5778e-02,\n",
      "         8.8347e-03,  2.6837e-02,  1.2663e-03, -5.5951e-02,  4.1020e-02,\n",
      "         2.6327e-03, -2.0245e-02,  1.3312e-03, -2.6611e-02, -5.0473e-02,\n",
      "        -7.4931e-03, -3.1155e-02,  1.5527e-02, -8.1276e-03,  8.5810e-03,\n",
      "         3.4451e-03, -9.2424e-04, -1.5369e-02, -2.3891e-02,  3.0609e-03,\n",
      "         1.9875e-02, -2.0956e-02,  4.5461e-03, -1.8391e-03,  4.4274e-02,\n",
      "         2.2567e-02, -6.0370e-03,  1.2496e-02,  2.0746e-03, -1.0946e-02,\n",
      "         2.0650e-02,  2.5806e-02, -1.9278e-02,  1.4566e-02,  3.5976e-03,\n",
      "        -1.2217e-03, -3.8044e-03,  1.2133e-02,  1.5179e-02,  1.8196e-02,\n",
      "         2.5570e-02,  3.3933e-02, -4.6378e-03, -1.3148e-02, -2.0486e-02,\n",
      "         1.2639e-02,  4.4519e-03, -9.2443e-03,  6.1674e-03, -2.8968e-03,\n",
      "        -1.6987e-02, -2.1071e-03,  1.9091e-03,  1.5211e-03, -2.6473e-02,\n",
      "         2.0642e-02, -1.8860e-02,  3.4914e-02, -1.1397e-02, -1.4059e-03,\n",
      "         1.3082e-02, -1.9104e-02, -2.0426e-02,  6.8402e-03, -1.5493e-02,\n",
      "         3.0338e-02, -1.1470e-02, -1.9168e-03,  9.1462e-03, -1.3863e-03,\n",
      "         2.6529e-02,  3.3494e-02,  2.3998e-02, -3.8264e-03,  9.4206e-03,\n",
      "         2.9821e-02,  3.8990e-03,  1.8075e-03, -4.0086e-02, -1.3733e-02,\n",
      "         2.7866e-02,  4.5698e-03, -1.6526e-02, -2.2030e-02,  5.8893e-03,\n",
      "        -1.3068e-02, -5.3202e-03,  6.9613e-03,  1.0254e-02,  9.7727e-03,\n",
      "        -1.3719e-02, -1.0652e-02,  2.6774e-02,  2.8054e-02, -3.5591e-03,\n",
      "         2.1948e-02, -2.4887e-02, -2.8158e-02, -4.0884e-03, -1.7388e-02,\n",
      "         5.4480e-03, -8.5015e-04,  1.9709e-03,  6.2734e-03, -1.4885e-02,\n",
      "        -1.7882e-02,  2.4589e-02,  2.3085e-03,  2.1265e-02, -4.8367e-02,\n",
      "        -4.7362e-03,  2.1979e-02, -2.6739e-02,  1.1028e-03,  8.5863e-04,\n",
      "        -1.4613e-02, -2.6722e-02,  4.2101e-02, -3.2523e-02,  1.0204e-02,\n",
      "        -3.4502e-02,  2.3504e-02, -2.9123e-02,  1.1598e-02,  7.5925e-03,\n",
      "        -1.4444e-02,  3.4625e-02,  2.3101e-02, -1.3849e-02,  1.1258e-02,\n",
      "        -4.5320e-02, -1.9878e-02,  2.0950e-02, -6.4392e-03,  1.9284e-02,\n",
      "        -2.0971e-03,  6.0509e-03, -1.8089e-02, -2.1971e-02, -6.3693e-03,\n",
      "        -2.0354e-02,  3.5922e-02,  3.5932e-02, -2.1090e-02,  4.2314e-04,\n",
      "         7.1389e-03,  8.0493e-03,  2.3290e-02, -8.3276e-03,  9.4543e-03,\n",
      "         1.8092e-02,  3.3560e-02, -5.6825e-03,  2.0516e-02,  3.4898e-02,\n",
      "        -7.0703e-03,  3.7362e-02,  2.7657e-02, -1.3936e-02, -2.6319e-02,\n",
      "        -1.3908e-02, -1.8677e-02,  2.3852e-02,  1.6976e-02,  1.5327e-02,\n",
      "        -6.0879e-03,  2.2005e-02, -4.0243e-03, -1.1714e-02,  2.0410e-02,\n",
      "        -1.8497e-02,  8.5107e-03, -8.6564e-03, -2.4225e-02, -2.0033e-03,\n",
      "         6.3995e-03,  2.9555e-02, -1.5593e-02,  1.0181e-02, -8.5003e-03,\n",
      "         5.7436e-03, -7.7306e-04, -2.3561e-02,  1.1536e-02,  2.4822e-03,\n",
      "         2.5618e-02, -2.6085e-02, -2.3701e-02,  3.3647e-02,  1.0572e-02,\n",
      "        -2.4800e-02, -2.2726e-02, -1.2326e-02, -3.2210e-02, -1.5953e-03,\n",
      "         7.5591e-03,  1.3244e-02, -7.9076e-03, -1.0542e-02, -6.6230e-03,\n",
      "        -2.3271e-02, -3.9486e-02, -3.2677e-02,  9.1751e-03,  6.2421e-02,\n",
      "         2.2113e-02, -2.8932e-02,  3.2125e-02, -9.2766e-03,  3.5046e-02,\n",
      "        -1.9643e-02, -8.0083e-03, -3.2785e-02, -1.4091e-02, -8.0119e-03,\n",
      "        -1.0195e-02,  2.7847e-02,  4.6275e-02, -8.9021e-03, -1.7150e-02,\n",
      "        -1.4626e-02,  2.5518e-02,  1.1028e-02, -1.1121e-02,  7.9729e-03,\n",
      "         1.8273e-02, -1.0318e-03, -5.9978e-03,  1.0250e-02,  6.8015e-03,\n",
      "         2.1158e-02, -2.9759e-03, -5.5975e-02, -1.2184e-02, -3.1431e-02,\n",
      "        -3.8803e-02,  9.1146e-03, -7.9919e-03, -1.9605e-02, -1.8929e-02,\n",
      "        -4.7021e-03, -1.0856e-02,  1.0552e-02, -1.4062e-02, -2.8066e-02,\n",
      "        -2.2740e-02,  4.6792e-03,  4.8006e-03, -2.0073e-02,  1.2456e-02,\n",
      "         1.8855e-03,  4.5036e-02,  6.9825e-03, -4.9253e-04,  1.1165e-02,\n",
      "        -3.2811e-03,  6.9603e-03, -1.0315e-02, -1.2541e-02, -7.1901e-03,\n",
      "        -5.2997e-03,  3.1422e-02,  2.0669e-03, -2.4999e-02, -1.8030e-02,\n",
      "        -9.5183e-03,  1.0302e-02,  1.8666e-02,  1.1196e-02, -1.6109e-02,\n",
      "         1.9013e-02, -2.3939e-02, -1.7553e-02, -1.7843e-02, -2.7076e-02,\n",
      "        -4.3090e-03, -2.9250e-04, -5.0448e-04, -2.6676e-03,  3.0656e-02,\n",
      "        -2.3040e-02, -3.8632e-02, -1.1900e-02,  4.9893e-04, -1.2856e-02,\n",
      "        -3.4682e-02,  1.2836e-03,  5.4804e-03,  1.3644e-02,  9.2513e-03,\n",
      "        -8.2963e-03,  3.4394e-03, -1.5778e-02,  6.9751e-03, -6.1536e-03,\n",
      "         8.7187e-04,  2.8202e-02, -6.1797e-03,  6.1976e-04, -7.7642e-03,\n",
      "        -6.4187e-03, -3.0483e-02,  6.4202e-03,  7.2555e-03, -7.7223e-03,\n",
      "        -1.6666e-02,  2.2078e-02, -5.1508e-02,  1.1128e-02, -2.1272e-03,\n",
      "        -1.7249e-02,  8.9574e-03,  5.2819e-02,  2.2429e-02, -1.7043e-02,\n",
      "        -2.7718e-03,  1.2007e-02, -2.0030e-02, -1.9817e-02,  1.9501e-02,\n",
      "         7.8226e-03, -1.5166e-02, -8.6329e-03, -2.3719e-02,  1.1606e-03,\n",
      "        -6.6655e-03,  3.8273e-02, -3.4380e-02, -9.8585e-03, -8.5054e-03,\n",
      "         2.9516e-03,  5.6217e-03,  4.1037e-02,  2.8637e-02, -3.2973e-02,\n",
      "        -2.3584e-02,  1.4307e-02, -1.5378e-02,  6.7922e-03, -2.3985e-02,\n",
      "        -2.1268e-04, -6.2882e-03,  1.8850e-03, -1.5289e-02,  1.0655e-03,\n",
      "         1.1029e-02,  5.2177e-02,  9.1647e-03, -4.3809e-02,  1.8802e-02,\n",
      "         3.2212e-02, -1.3753e-02, -4.4581e-02,  7.0408e-03,  3.7225e-03,\n",
      "        -1.0844e-02, -2.2083e-02, -1.6518e-02, -5.2206e-02, -1.1206e-02,\n",
      "        -4.8756e-03,  7.5974e-03,  2.3535e-02], grad_fn=<SliceBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, CamembertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "print(len(tokenizer))  # 28996\n",
    "tokenizer.add_tokens([\"NEW_TOKEN\"])\n",
    "print(len(tokenizer))  # 28997\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer)) \n",
    "# The new vector is added at the end of the embedding matrix\n",
    "\n",
    "print(model.embeddings.word_embeddings.weight[-1, :])\n",
    "# Randomly generated matrix\n",
    "\n",
    "model.embeddings.word_embeddings.weight[-1, :] = torch.zeros([model.config.hidden_size])\n",
    "\n",
    "print(model.embeddings.word_embeddings.weight[-1, :])\n",
    "# outputs a vector of zeros of shape [768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2898774a844932a8bc3e7d79c5110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=808767.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, CamembertTokenizer\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁a',\n",
       " 'den',\n",
       " 'ome',\n",
       " ',',\n",
       " '▁ad',\n",
       " 's',\n",
       " 'or',\n",
       " 'p',\n",
       " 'tion',\n",
       " ',',\n",
       " '▁maladie',\n",
       " ',',\n",
       " '▁a',\n",
       " 's',\n",
       " 'thé',\n",
       " 'nie',\n",
       " ',',\n",
       " '▁brad',\n",
       " 'y',\n",
       " 'cardi',\n",
       " 'e',\n",
       " ',',\n",
       " '▁rhum',\n",
       " 'e',\n",
       " ',',\n",
       " '▁mal',\n",
       " '▁de',\n",
       " '▁ventre',\n",
       " ',',\n",
       " '▁digestif',\n",
       " ',',\n",
       " '▁clé',\n",
       " ',',\n",
       " '▁',\n",
       " 'eczéma',\n",
       " ',',\n",
       " '▁fur',\n",
       " 'on',\n",
       " 'cle',\n",
       " ',',\n",
       " '▁oncle',\n",
       " ',',\n",
       " '▁respiration',\n",
       " ',',\n",
       " '▁B',\n",
       " 'PM']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"adenome, adsorption, maladie, asthénie, bradycardie, rhume, mal de ventre, digestif, clé, eczéma, furoncle, oncle, respiration, BPM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
