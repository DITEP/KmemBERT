{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer, pipeline, CamembertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"camembert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "cam = CamembertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\"J'ai passé une super journée\", \"Grosses galères aujourd'hui\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁J', \"'\", 'ai', '▁passé', '▁une', '▁super', '▁journée']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tweet)\n",
    "tokenizer.encode(tweet)\n",
    "tokenizer.decode(tokenizer.encode(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5105077624320984}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Il fait très beau !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForMaskedLM were not initialized from the model checkpoint at camembert-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s> Le camembert est délicieux :)</s>',\n",
       "  'score': 0.49091020226478577,\n",
       "  'token': 7200,\n",
       "  'token_str': '▁délicieux'},\n",
       " {'sequence': '<s> Le camembert est excellent :)</s>',\n",
       "  'score': 0.10556937754154205,\n",
       "  'token': 2183,\n",
       "  'token_str': '▁excellent'},\n",
       " {'sequence': '<s> Le camembert est succulent :)</s>',\n",
       "  'score': 0.034533143043518066,\n",
       "  'token': 26202,\n",
       "  'token_str': '▁succulent'},\n",
       " {'sequence': '<s> Le camembert est meilleur :)</s>',\n",
       "  'score': 0.03303135931491852,\n",
       "  'token': 528,\n",
       "  'token_str': '▁meilleur'},\n",
       " {'sequence': '<s> Le camembert est parfait :)</s>',\n",
       "  'score': 0.030076511204242706,\n",
       "  'token': 1654,\n",
       "  'token_str': '▁parfait'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camembert_fill_mask  = pipeline(\"fill-mask\", model=model_name, tokenizer=tokenizer)\n",
    "camembert_fill_mask(\"Le camembert est <mask> :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"<s> J'aime les yeux bleus!</s>\",\n",
       "  'score': 0.0990937277674675,\n",
       "  'token': 605,\n",
       "  'token_str': '▁yeux'},\n",
       " {'sequence': \"<s> J'aime les cheveux bleus!</s>\",\n",
       "  'score': 0.04541785269975662,\n",
       "  'token': 1277,\n",
       "  'token_str': '▁cheveux'},\n",
       " {'sequence': \"<s> J'aime les chats bleus!</s>\",\n",
       "  'score': 0.03782883286476135,\n",
       "  'token': 6289,\n",
       "  'token_str': '▁chats'},\n",
       " {'sequence': \"<s> J'aime les poissons bleus!</s>\",\n",
       "  'score': 0.035177621990442276,\n",
       "  'token': 4831,\n",
       "  'token_str': '▁poissons'},\n",
       " {'sequence': \"<s> J'aime les oiseaux bleus!</s>\",\n",
       "  'score': 0.026914037764072418,\n",
       "  'token': 5709,\n",
       "  'token_str': '▁oiseaux'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camembert_fill_mask(\"J'aime les <mask> bleus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(tweets, return_tensors='pt', padding=True, truncation=True)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = camembert(input_ids, attention_mask=attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7065, grad_fn=<NllLossBackward>), logits=tensor([[ 0.0557, -0.1002],\n",
       "        [ 0.0349, -0.0768]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('french_tweets_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df.label)\n",
    "texts = list(df.text)\n",
    "\n",
    "encoding = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "labels = torch.tensor(labels).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "camembert = CamembertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "optimizer = AdamW(camembert.parameters(), lr=1e-5)\n",
    "classifier = pipeline('sentiment-analysis', model=camembert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3633, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for _ in range(epochs):\n",
    "    outputs = camembert(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.6743533611297607},\n",
       " {'label': 'LABEL_0', 'score': 0.6857601404190063},\n",
       " {'label': 'LABEL_0', 'score': 0.6726309061050415},\n",
       " {'label': 'LABEL_0', 'score': 0.6749323606491089},\n",
       " {'label': 'LABEL_0', 'score': 0.6603058576583862},\n",
       " {'label': 'LABEL_0', 'score': 0.6522192358970642},\n",
       " {'label': 'LABEL_0', 'score': 0.6360929012298584},\n",
       " {'label': 'LABEL_1', 'score': 0.7538371086120605},\n",
       " {'label': 'LABEL_1', 'score': 0.7436507940292358},\n",
       " {'label': 'LABEL_1', 'score': 0.7174726724624634},\n",
       " {'label': 'LABEL_1', 'score': 0.7531613707542419},\n",
       " {'label': 'LABEL_1', 'score': 0.674791157245636},\n",
       " {'label': 'LABEL_1', 'score': 0.6971939206123352},\n",
       " {'label': 'LABEL_1', 'score': 0.7637169361114502},\n",
       " {'label': 'LABEL_1', 'score': 0.750148355960846},\n",
       " {'label': 'LABEL_1', 'score': 0.7579358816146851}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
